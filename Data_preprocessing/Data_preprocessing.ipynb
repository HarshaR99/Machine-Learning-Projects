{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZ3_sC5_gdl",
        "colab_type": "text"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgYmhim4RC8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xoQTJ6pRMu1",
        "colab_type": "text"
      },
      "source": [
        "#Loading Dataset\n",
        "As dataset is a matrix(2-D array), for splicing use syntax [:(to select rows) , :(for columns)] for n-dim use [:,:,......,:]\n",
        "\n",
        "***iloc*** (Index loaction) is a function in pandas. It will take indexes of rows and columns we want to extract in dataset.\n",
        "\n",
        "***Feature variables*** in the first n-1 columns.\n",
        "\n",
        "The ***dependent variable vector*** is in the nth (last column)\n",
        "\n",
        "We have ***values*** after iloc because we are taking the values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Z_dACcRQL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "f1305896-4945-4d69-b670-789e0daad721"
      },
      "source": [
        "#loading dataset from github\n",
        "url = 'https://raw.githubusercontent.com/HarshaR99/Machine_Learning_Course/master/Data_preprocessing/Data.csv?token=AMM77XYADHGGPSB47LHI4Z27AWAJK'\n",
        "#url needs to be updated during every run\n",
        "dataset = pd.read_csv(url)\n",
        "x = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values\n",
        "print(x,'\\n')\n",
        "print(y,'\\n')\n",
        "#comparison without using values attr\n",
        "print(dataset.iloc[:,:-1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]] \n",
            "\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes'] \n",
            "\n",
            "   Country   Age   Salary\n",
            "0   France  44.0  72000.0\n",
            "1    Spain  27.0  48000.0\n",
            "2  Germany  30.0  54000.0\n",
            "3    Spain  38.0  61000.0\n",
            "4  Germany  40.0      NaN\n",
            "5   France  35.0  58000.0\n",
            "6    Spain   NaN  52000.0\n",
            "7   France  48.0  79000.0\n",
            "8  Germany  50.0  83000.0\n",
            "9   France  37.0  67000.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts2H5IN_Zyl3",
        "colab_type": "text"
      },
      "source": [
        "#Tacking care of missing data\n",
        "In statistics, ***imputation*** is the process of replacing missing data with substituted values.\n",
        "[Documentation here](https://scikit-learn.org/0.16/modules/generated/sklearn.preprocessing.Imputer.html#sklearn.preprocessing.Imputer.fit)\n",
        "\n",
        "In dataframe missing value is represented as ***nan*** of numpy and we are replacing numeric missing data by the mean (can be median,etc) of the column hence *missing_values*=np.nan, *strategy*='mean'.\n",
        "\n",
        "***fit()*** method fits the imputer on ***x***(feature vairables), connects imputer to matrix of features.\n",
        "\n",
        "***transform(***) method will do the *replacement* of *missing* data in numeric columns and will return the respective columns.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUroVgzecLvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "af6c183e-1894-4e12-8659-f5cdffe7d8ce"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "# for fit pass all rows but only numeric columns\n",
        "imputer.fit(x[:,1:3])\n",
        "x[:,1:3] = imputer.transform(x[:,1:3])\n",
        "# notice missing values filled\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH-niF09mwK_",
        "colab_type": "text"
      },
      "source": [
        "#Encoding Categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76djuJXim7FK",
        "colab_type": "text"
      },
      "source": [
        "##Encoding the independant variable\n",
        "\n",
        "If we simply assign some number to different categories the model might think their is a numerical order(misinterpreted correlation) among them so we use onehotencoding.\n",
        "\n",
        "*Sometimes in datasets, we encounter columns that contain numbers of no specific order of preference. The data in the column usually denotes a category or value of the category and also when the data in the column is label encoded.* ~ geeksforgeeks.\n",
        "\n",
        "---\n",
        "In ColumnTransformer encoder is the type of tranformatiom\n",
        "OneHotEncoder is the type of encoding we will do\n",
        "The list at the end is the index of columns which will undergo this transformation.\n",
        "\n",
        "Remainder is wheter we keep the remaining columns or not which are not being encoded.\n",
        "\n",
        "*To train the model it should be in form of numpy array so after transformng convert it to numpy array*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRwOfoeQqg9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "ec7e14c8-91f4-4d75-d54a-6fa00add18e1"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))\n",
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKIol24EvpRE",
        "colab_type": "text"
      },
      "source": [
        "##Encoding the dependant variable\n",
        "Just using a label encoder like yes/no = 1/0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW5_zEpxubSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01681790-233d-4b44-9ddd-912bd5ad2698"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucs24oyBWkLn",
        "colab_type": "text"
      },
      "source": [
        "#Splitting dataset into training and test set\n",
        "\n",
        "[About random state.](https://)\n",
        "\n",
        "Test size is 20% of dataset.\n",
        "Training size is 80%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1_bahu4WqvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSpewNmOgRsG",
        "colab_type": "text"
      },
      "source": [
        "#Feature scaling\n",
        "It refers to putting the values in the same range or same scale so that no variable is dominated by the other.\n",
        "\n",
        "No need to fit again for testing set as standard derivation and mean should be same for both testing and training set.\n",
        "\n",
        "standardisation = (x - mean(x)) /starndard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8m3YxkUgT8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train[:,3:] = sc.fit_transform(x_train[:,3:])\n",
        "x_test[:,3:] = sc.transform(x_test[:,3:])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mep2qvQpgz-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "23303461-48f9-4cb0-8ba3-946d1206bea9"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}